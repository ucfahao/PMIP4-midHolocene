{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/geog0111/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/anaconda/envs/geog0111/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ucfaccb/Documents/local_repos/PMIP4-midHolocene/pseudocorals/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "import xarray as xr\n",
    "import netCDF4 as nc4\n",
    "import scipy.io as io\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "base = os.getcwd()+\"/\"\n",
    "print(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_names(filenames, model_list):\n",
    "\n",
    "    '''\n",
    "    Gets a list of available models (midHolocene & piControl) from the \n",
    "    curated_ESGF replica directory. \n",
    "\n",
    "    INPUTS:\n",
    "        - filenames: list, a file glob of the available sos & tos files\n",
    "        - model_list: list, an empty list to put the model names in\n",
    "\n",
    "    RETURNS:\n",
    "        - Nothing\n",
    "\n",
    "    '''\n",
    "\n",
    "    for path in filenames:\n",
    "        model_name = path.split('/')[4]\n",
    "        model_list.append(model_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_filenames_mh = glob.glob('/data/CMIP/curated_ESGF_replica/*/midHolocene/sos*.nc')\n",
    "sos_filenames_ctrl = glob.glob('/data/CMIP/curated_ESGF_replica/*/piControl/sos*.nc')\n",
    "sos_filenames_hi = glob.glob('/data/CMIP/curated_ESGF_replica/*/historical/sos*.nc')\n",
    "tos_filenames_mh = glob.glob('/data/CMIP/curated_ESGF_replica/*/midHolocene/tos*.nc')\n",
    "tos_filenames_ctrl = glob.glob('/data/CMIP/curated_ESGF_replica/*/piControl/tos*.nc')  \n",
    "tos_filenames_hi = glob.glob('/data/CMIP/curated_ESGF_replica/*/historical/tos*.nc')\n",
    "\n",
    "sos_models_mh=[]\n",
    "sos_models_ctrl=[]\n",
    "sos_models_hi=[]\n",
    "tos_models_mh=[]\n",
    "tos_models_ctrl=[]\n",
    "tos_models_hi=[]\n",
    "\n",
    "get_model_names(sos_filenames_mh, sos_models_mh)\n",
    "get_model_names(sos_filenames_ctrl, sos_models_ctrl)\n",
    "get_model_names(sos_filenames_hi, sos_models_hi)\n",
    "get_model_names(tos_filenames_mh, tos_models_mh)\n",
    "get_model_names(tos_filenames_ctrl, tos_models_ctrl)  \n",
    "get_model_names(tos_filenames_hi, tos_models_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(sos_models, tos_models, expt, var, array_list, model_namelist):\n",
    "    \n",
    "    '''\n",
    "    Opens up the sos and tos files into x-array datasets.\n",
    "    \n",
    "    INPUTS:\n",
    "        - sos_models, tos_models: list of model names\n",
    "        - expt: string, midHolocene or piControl\n",
    "        - var: string, sos or tos\n",
    "        - array_list: list to put x_array dataset in\n",
    "        - model_namelist: empty list, to put new model names in\n",
    "    \n",
    "    RETURNS:\n",
    "        - Nothing\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # are both sos and tos present in piControl/midHolocene folders?\n",
    "    for model in sos_models:\n",
    "        if model in tos_models:\n",
    "                                                # {model}{expt}{var}\n",
    "            fn_format= \"/data/CMIP/curated_ESGF_replica/{}/{}/{}*.nc\"\n",
    "            # make a file-glob by putting the model into format\n",
    "            files = fn_format.format(model, expt, var)\n",
    "            print(files)\n",
    "\n",
    "            # open datasets & put them in a list\n",
    "            for fname in glob.iglob(files):\n",
    "                array_list.append(xr.open_dataset(fname))\n",
    "                \n",
    "            model_namelist.append(model)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/CMIP/curated_ESGF_replica/CESM2/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/GISS-E2-1-G/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/HadGEM3-GC31/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/IPSL-CM6A-LR/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NESM3/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MRI-ESM2-0/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MIROC-ES2L/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM1-F/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/UofT-CCSM-4/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-f3-L/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/INM-CM4-8/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-g3/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM2-LM/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/EC-Earth3-LR/midHolocene/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MPI-ESM1-2-LR/midHolocene/sos*.nc\n",
      "\n",
      "\n",
      "/data/CMIP/curated_ESGF_replica/CESM2/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/GISS-E2-1-G/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/HadGEM3-GC31/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/IPSL-CM6A-LR/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NESM3/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MRI-ESM2-0/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MIROC-ES2L/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM1-F/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/UofT-CCSM-4/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-f3-L/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/INM-CM4-8/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-g3/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM2-LM/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/EC-Earth3-LR/midHolocene/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MPI-ESM1-2-LR/midHolocene/tos*.nc\n",
      "\n",
      "\n",
      "/data/CMIP/curated_ESGF_replica/CESM2/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/GISS-E2-1-G/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/HadGEM3-GC31/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/IPSL-CM6A-LR/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NESM3/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MRI-ESM2-0/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MIROC-ES2L/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM1-F/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/UofT-CCSM-4/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-f3-L/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/INM-CM4-8/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-g3/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM2-LM/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/EC-Earth3-LR/piControl/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MPI-ESM1-2-LR/piControl/sos*.nc\n",
      "\n",
      "\n",
      "/data/CMIP/curated_ESGF_replica/CESM2/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/GISS-E2-1-G/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/HadGEM3-GC31/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/IPSL-CM6A-LR/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NESM3/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MRI-ESM2-0/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MIROC-ES2L/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM1-F/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/UofT-CCSM-4/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-f3-L/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/INM-CM4-8/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-g3/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM2-LM/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/EC-Earth3-LR/piControl/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MPI-ESM1-2-LR/piControl/tos*.nc\n",
      "\n",
      "\n",
      "/data/CMIP/curated_ESGF_replica/CESM2/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/GISS-E2-1-G/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/HadGEM3-GC31/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/IPSL-CM6A-LR/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NESM3/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MRI-ESM2-0/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MIROC-ES2L/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-f3-L/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/INM-CM4-8/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-g3/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM2-LM/historical/sos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MPI-ESM1-2-LR/historical/sos*.nc\n",
      "\n",
      "\n",
      "/data/CMIP/curated_ESGF_replica/CESM2/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/GISS-E2-1-G/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/HadGEM3-GC31/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/IPSL-CM6A-LR/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NESM3/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MRI-ESM2-0/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MIROC-ES2L/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-f3-L/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/INM-CM4-8/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/FGOALS-g3/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/NorESM2-LM/historical/tos*.nc\n",
      "/data/CMIP/curated_ESGF_replica/MPI-ESM1-2-LR/historical/tos*.nc\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "new_sos_models_mh=[]\n",
    "new_sos_models_ctrl=[]\n",
    "new_sos_models_hi=[]\n",
    "new_tos_models_mh=[]\n",
    "new_tos_models_ctrl=[]\n",
    "new_tos_models_hi=[]\n",
    "\n",
    "sos_data_mh = []\n",
    "sos_data_ctrl = []\n",
    "sos_data_hi = []\n",
    "tos_data_mh = []\n",
    "tos_data_ctrl = []\n",
    "tos_data_hi = []\n",
    "\n",
    "get_filenames(sos_models_mh, tos_models_mh, 'midHolocene', 'sos', sos_data_mh, \n",
    "              new_sos_models_mh)\n",
    "get_filenames(sos_models_mh, tos_models_mh, 'midHolocene', 'tos', tos_data_mh, \n",
    "              new_tos_models_mh)\n",
    "get_filenames(sos_models_ctrl, tos_models_ctrl, 'piControl', 'sos', sos_data_ctrl, \n",
    "              new_sos_models_ctrl)\n",
    "get_filenames(sos_models_ctrl, tos_models_ctrl, 'piControl', 'tos', tos_data_ctrl, \n",
    "              new_tos_models_ctrl)\n",
    "get_filenames(sos_models_hi, tos_models_hi, 'historical', 'sos', sos_data_hi, \n",
    "              new_sos_models_hi)\n",
    "get_filenames(sos_models_hi, tos_models_hi, 'historical', 'tos', tos_data_hi, \n",
    "              new_tos_models_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def get_coord_names(fx):\n",
    "    \n",
    "    '''\n",
    "    Discovers what the lat/lon variable in a dataset is called and returns this\n",
    "    as an array. Also converts -180-->180 deg longitudes to 0-->360 deg\n",
    "    longitudes.\n",
    "    \n",
    "    INPUTS:\n",
    "        - fx: xarray DataSet e.g. sos_data_ctrl[0]\n",
    "\n",
    "    RETURNS:\n",
    "        - lat: array of latitudes\n",
    "        - lon: array of longitudes \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # work out what lat/lon var is called\n",
    "    if 'lat' in fx.variables:\n",
    "        lat = fx.variables['lat'].values\n",
    "        lon = fx.variables['lon'].values\n",
    "        if lon.max() < 300: # convert -180-->180 lons to 0-->360 lons\n",
    "            lon %= 360\n",
    "\n",
    "    elif 'nav_lat' in fx.variables:\n",
    "        lat = fx.variables['nav_lat'].values\n",
    "        lon = fx.variables['nav_lon'].values\n",
    "        if lon.max() < 300:\n",
    "            lon %= 360\n",
    "\n",
    "    elif 'latitude' in fx.variables:\n",
    "        lat = fx.variables['latitude'].values\n",
    "        lon = fx.variables['longitude'].values\n",
    "        if lon.max() < 300:\n",
    "            lon %= 360\n",
    "     \n",
    "    else:\n",
    "        print(\"!!LAT/LON VAR NAME NOT RECOGNISED!!\")\n",
    "        \n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def get_curvi_coords(fx, var, min_lat, max_lat, min_lon, max_lon, verbose):\n",
    "    \n",
    "    '''\n",
    "    This code was developed by Damian Oyarzun Valenzuela, PhD candidate, \n",
    "    Geography UCL, 2017.\n",
    "    \n",
    "    Returns variable over a specific lat-lon region by taking a subset\n",
    "    of the curvilinear coords i.e. for a variable X:\n",
    "        latitude.shape = (y.y)\n",
    "        longitude.shape = (x.x)\n",
    "    \n",
    "    INPUTS:\n",
    "        - fx: xarray DataSet e.g. sos_data_ctrl[0]\n",
    "        - var: xarray DataArray e.g. sos_data_ctrl[0].sos\n",
    "        - min_lat: the minimum latitude (deg N)\n",
    "        - max_lat: the maximum latitude (deg N)\n",
    "        - min_lon: the minimum longitude (deg E)\n",
    "        - max_lon: the maximum longitude (deg E)\n",
    "        - verbose: if True, calculate the variable (e.g. sos) over the AOI,\n",
    "                   if False, calculate the lat/lon variable over the AOI \n",
    "                   (curvilinear coords)\n",
    "    \n",
    "    RETURNS:\n",
    "        - var_ai: var in a specific lat-lon region\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print('***getting curvi coordinates***')\n",
    "    \n",
    "    area = [min_lat, max_lat, min_lon, max_lon]  \n",
    "    lat, lon = get_coord_names(fx)\n",
    "\n",
    "    # Specify area of interest as lat-lon degrees\n",
    "    # Produces boolean array \n",
    "    latt = np.logical_and(lat >= area[0], lat <= area[1])\n",
    "    lonn = np.logical_and(lon >= area[2], lon <= area[3])\n",
    "\n",
    "    # Select area of interest from combination of lat-lon arrays\n",
    "    # Produces boolean array\n",
    "    a_int = latt * lonn \n",
    "\n",
    "    # Indices for area of interest\n",
    "    # nonzero returns indices of elements that are non-zero (True)\n",
    "    (ii,jj) = a_int.nonzero()\n",
    "    \n",
    "    if verbose:\n",
    "        # Var over AOI\n",
    "        # shape change: e.g. (8400, 384, 320) --> (8400, 185, 239)\n",
    "        var_ai = var[:, ii.min():ii.max(),jj.min():jj.max()] \\\n",
    "                     *a_int[ii.min():ii.max(),jj.min():jj.max()]\n",
    "        \n",
    "        '''        \n",
    "        # Show lat/lon field\n",
    "        # Boolean array, var*AOI, var over AOI only  \n",
    "        vvv = [a_int, var[0,:,:]*a_int, var_ai[0,:,:]]\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 2))\n",
    "        for vv,ax in zip(vvv,axes.flat):\n",
    "            im = ax.imshow(vv, origin=(20,10)) \n",
    "        '''\n",
    "            \n",
    "    else:\n",
    "        # Coords over AOI\n",
    "        # shape change: e.g. (384, 320) --> (185, 239)\n",
    "        var_ai = var[ii.min():ii.max(),jj.min():jj.max()] \\\n",
    "                     *a_int[ii.min():ii.max(),jj.min():jj.max()]\n",
    "        \n",
    "        '''       \n",
    "        # Show lat/lon field\n",
    "        # Boolean array, var*AOI, var over AOI only  \n",
    "        vvv = [a_int, var[:,:]*a_int, var_ai[:,:]]\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 2))\n",
    "        for vv,ax in zip(vvv,axes.flat):\n",
    "            im = ax.imshow(vv, origin=(20,10))\n",
    "        '''\n",
    "    \n",
    "    print(var.shape, '-->', var_ai.shape)\n",
    "    print('***finished curvi coordinates***')\n",
    "    \n",
    "    return var_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def get_pacific_coords(lat, lon, fs, ft, start_lat, end_lat, start_lon, end_lon):\n",
    "    \n",
    "    '''\n",
    "    Determines whether lat/lon variable is rectilinear or curvilinear. If the\n",
    "    former, it selects a subset of the variable according to a start_lat,\n",
    "    end_lat, start_lon and end_lon. It then takes the subsequent lat/lon coord \n",
    "    as the lat/lon object. If the latter, it works out a subset of the variable \n",
    "    and lat/lon variable using the get_curvi_coords function. To gain a subset of\n",
    "    the lat/lon coordinates, it works out what the lat/lon variable is called\n",
    "    in the file.\n",
    "     \n",
    "    INPUTS:\n",
    "        - lat: array of latitudes, e.g. fx.variables['lat'].values\n",
    "        - lon: array of longitudes, e.g. fx.variables['lon'].values\n",
    "        - start_lat: the minimum latitude (deg N)\n",
    "        - end_lat: the maximum latitude (deg N)\n",
    "        - start_lon: the minimum longitude (deg E)\n",
    "        - end_lon: the maximum longitude (deg E)    \n",
    "        - fs, ft: xarray DataSet e.g. tos_data_ctrl[0]\n",
    "    \n",
    "    RETURNS:\n",
    "        - IPsosVar, IPtosVar: var in a specific lat-lon region\n",
    "        - sos_latobj: latitude in a specific lat-lon region\n",
    "        - sos_lonobj: longitude in a specific lat-lon region\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # rectilinear\n",
    "    #try:\n",
    "    if len(lat.shape) == 1:\n",
    "        IPsosVar = fs.sos.sel(lat=slice(start_lat, end_lat), \n",
    "                              lon=slice(start_lon, end_lon))\n",
    "        IPtosVar = ft.tos.sel(lat=slice(start_lat, end_lat), \n",
    "                              lon=slice(start_lon, end_lon))\n",
    "        sos_latobj = IPsosVar.lat\n",
    "        sos_lonobj = IPsosVar.lon\n",
    "\n",
    "    # curvilinear\n",
    "    else:\n",
    "        IPsosVar = get_curvi_coords(fs, fs.sos, start_lat, end_lat, \n",
    "                                    start_lon, end_lon, verbose=True)\n",
    "        IPtosVar = get_curvi_coords(ft, ft.tos, start_lat, end_lat, \n",
    "                                    start_lon, end_lon, verbose=True)\n",
    "        \n",
    "        if 'lat' in fs.variables:\n",
    "            sos_latobj = get_curvi_coords(fs, fs.lat, start_lat, end_lat, \n",
    "                                          start_lon, end_lon, verbose=False)\n",
    "            sos_lonobj = get_curvi_coords(ft, ft.lon, start_lat, end_lat, \n",
    "                                          start_lon, end_lon, verbose=False)\n",
    "\n",
    "        elif 'nav_lat' in fs.variables:\n",
    "            sos_latobj = get_curvi_coords(fs, fs.nav_lat, start_lat, end_lat, \n",
    "                                          start_lon, end_lon, verbose=False)\n",
    "            sos_lonobj = get_curvi_coords(ft, ft.nav_lon, start_lat, end_lat, \n",
    "                                          start_lon, end_lon, verbose=False)\n",
    "\n",
    "        elif 'latitude' in fs.variables:\n",
    "            sos_latobj = get_curvi_coords(fs, fs.latitude, start_lat, end_lat, \n",
    "                                          start_lon, end_lon, verbose=False)\n",
    "            sos_lonobj = get_curvi_coords(ft, ft.longitude, start_lat, end_lat, \n",
    "                                          start_lon, end_lon, verbose=False)\n",
    "    \n",
    "    return IPsosVar, IPtosVar, sos_latobj, sos_lonobj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute corals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def coral_sensor_field(latArray, lonArray, sst, sss):\n",
    "    \n",
    "    '''  \n",
    "    This function implements the bivariate model of [1] to SST and SSS fields.\n",
    "    Adapted from: https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/pmip3_pcoral.py\n",
    "    \n",
    "    INPUTS:  \n",
    "        - latArray, lonArray, numpy 1D arrays\n",
    "        - sst (in K or degC), masked array\n",
    "        - sss (in psu*), masked array\n",
    "        \n",
    "    RETURNS\n",
    "        - coral, the pseudocoral at the same locations as SST, SSS\n",
    "        - tosContri, the thermal contribution\n",
    "        - sosContri, the hydrological contribution\n",
    "\n",
    "    * assumes SSS in psu, so need to convert if this is not the case \n",
    "      \n",
    "    [1] Thompson, D. M. , T. R. Ault , M. N. Evans , J. E. Cole , \n",
    "    and J. Emile-Geay (2011), Comparison of observed and simulated tropical \n",
    "    climate trends using a forward model of coral δ18O, Geophys. Res. \n",
    "    Lett., 38, L14706, doi:10.1029/2011GL048224.  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print('***doing coral_sensor_field***')\n",
    "    print('centering the fields')\n",
    "    # center the fields\n",
    "    nt, ny, nx = sss.shape\n",
    "    # Mean over time\n",
    "    sss_m = ma.mean(sss, axis=0)\n",
    "    sss_c = sss - np.tile(sss_m, (nt,1,1)) \n",
    "    sst_m = ma.mean(sst, axis=0)\n",
    "    sst_c = sst - np.tile(sst_m, (nt,1,1)) \n",
    "    \n",
    "    print('assigning b-values')\n",
    "    # assign different b values based on location\n",
    "    a = -0.22\n",
    "    b1 = 0.3007062\n",
    "    b2 = 0.1552032\n",
    "    b3 = 0.2619054\n",
    "    b4 = 0.436509\n",
    "    \n",
    "    b = np.empty((len(latArray),len(lonArray)))\n",
    "    for lat in range(len(latArray)):\n",
    "        for lon in range(len(lonArray)):\n",
    "            #Red sea\n",
    "            if lonArray[lon]>=32.83 and lonArray[lon]<=43.5 and \\\n",
    "            latArray[lat]>=12.38 and latArray[lat]<=28.5:\n",
    "                b[lat][lon]=b1\n",
    "            #Indian ocean\n",
    "            elif lonArray[lon]<=120:\n",
    "                b[lat][lon]=b2\n",
    "            #Tropical Pacific\n",
    "            elif latArray[lat]>= -5 and latArray[lat]<=13:\n",
    "                b[lat][lon]=b3\n",
    "            #South Pacific\n",
    "            elif latArray[lat]< -5:\n",
    "                b[lat][lon]=b4\n",
    "            #Default: Tropical Pacific\n",
    "            else:\n",
    "                b[lat][lon]=b3\n",
    "\n",
    "    print('storing b-values')\n",
    "    # store coordinates of four b values seperately\n",
    "    b1_index = np.where(b == b1)\n",
    "    b2_index = np.where(b == b2)\n",
    "    b3_index = np.where(b == b3)\n",
    "    b4_index = np.where(b == b4)\n",
    "\n",
    "    # create a new array with the same shape as IPsos and compute coral\n",
    "    coral = np.empty_like(sss)\n",
    "    tosContri = np.empty_like(sst)\n",
    "    sosContri = np.empty_like(sss)\n",
    "    \n",
    "    print('calculating contributions')\n",
    "    # hydrological contribution\n",
    "    for b_index, b in ((b1_index, b1), (b2_index, b2), \n",
    "                       (b3_index, b3), (b4_index, b4)):\n",
    "        sosContri[:, b_index[0], b_index[1]] = b * sss_c[:, b_index[0], \n",
    "                                                         b_index[1]]\n",
    "        \n",
    "    # thermal contribution    \n",
    "    tosContri = a * sst_c\n",
    "    \n",
    "    # total contribution\n",
    "    coral = sosContri + tosContri\n",
    "    \n",
    "    print('***finished coral_sensor_field***')\n",
    "    \n",
    "    # export all three\n",
    "    return coral, tosContri, sosContri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def compute_corals(IPsosVar, IPtosVar, sos_latobj, sos_lonobj):\n",
    "    \n",
    "    '''  \n",
    "    This function implements the bivariate model of [1] to SST and SSS fields.\n",
    "    Adapted from: https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/pmip3_pcoral.py\n",
    "    \n",
    "    INPUTS:  \n",
    "        - IPsosVar, IPtosVar: var in a specific lat-lon region\n",
    "        - sos_latobj: latitude in a specific lat-lon region\n",
    "        - sos_lonobj: longitude in a specific lat-lon region\n",
    "        \n",
    "    RETURNS\n",
    "        - tobj: the time variable\n",
    "        - sos_latobj: latitude in a specific lat-lon region\n",
    "        - sos_lonobj: longitude in a specific lat-lon region\n",
    "        - coral2: the pseudocoral at the same locations as SST, SSS\n",
    "        - tosContri: the thermal contribution\n",
    "        - sosContri: the hydrological contribution\n",
    "        \n",
    "    * assumes SSS in psu, so need to convert if this is not the case \n",
    "      \n",
    "    [1] Thompson, D. M. , T. R. Ault , M. N. Evans , J. E. Cole , \n",
    "    and J. Emile-Geay (2011), Comparison of observed and simulated tropical \n",
    "    climate trends using a forward model of coral δ18O, Geophys. Res. \n",
    "    Lett., 38, L14706, doi:10.1029/2011GL048224.  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print('***starting compute_corals***')\n",
    "\n",
    "    # define missing values\n",
    "    ma.set_fill_value(IPsosVar, 1e20)\n",
    "    ma.set_fill_value(IPtosVar, 1e20)\n",
    "\n",
    "    # load into arrays\n",
    "    IPsos = IPsosVar.values\n",
    "    IPtos = IPtosVar.values\n",
    "\n",
    "    # get the values for computations\n",
    "    sos_ma = ma.masked_equal(IPsos, 1e20)\n",
    "    sos_ma = ma.array(sos_ma, mask=np.isnan(sos_ma))\n",
    "    tos_ma = ma.masked_equal(IPtos, 1e20)\n",
    "    tos_ma = ma.array(tos_ma, mask=np.isnan(tos_ma))\n",
    "\n",
    "    # get the means map\n",
    "    sos_mean = ma.mean(sos_ma, axis=0)\n",
    "    tos_mean = ma.mean(tos_ma, axis=0)\n",
    "\n",
    "    # total means no seasonal cycle is removed from the computation\n",
    "    sos_mean_total = ma.mean(sos_ma)\n",
    "    if sos_mean_total <= 1:   #  MORE SOPHISTICATED EXCEPTION HANDLING HERE?\n",
    "        print ('times sos by 1000')\n",
    "        sos_ma = sos_ma * 1000\n",
    "\n",
    "    tobj = IPsosVar.time\n",
    "    timeArray = tobj.values\n",
    "\n",
    "    print('creating lat/lon arrays')\n",
    "    # detect whether variable is in curvilinear grid\n",
    "    # curvilinear\n",
    "    if len(sos_latobj.shape) == 2:\n",
    "        latArray = sos_latobj[:,0]\n",
    "        lonArray = sos_lonobj[0,:]\n",
    "    # rectangular\n",
    "    else:\n",
    "        latArray = sos_latobj\n",
    "        lonArray = sos_lonobj\n",
    "\n",
    "    # apply coral sensor model \n",
    "    coral, tosContri, sosContri = coral_sensor_field(latArray, lonArray, \n",
    "                                                     tos_ma, sos_ma)\n",
    "\n",
    "    print('creating masked arrays')\n",
    "    coral2 = ma.masked_equal(coral, 1e20) # coral2.shape = 1200, 30, 108\n",
    "    tosContri = ma.masked_equal(tosContri, 1e20)\n",
    "    sosContri = ma.masked_equal(sosContri, 1e20)\n",
    "    \n",
    "    print('***finished compute_corals***')\n",
    "\n",
    "    return tobj, sos_latobj, sos_lonobj, coral2, tosContri, sosContri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def coral_sensor_apply(ft, fs, expt, model):\n",
    "    \n",
    "    '''\n",
    "    This function converts model output to pseudocoral, according to the \n",
    "    bivariate model of [1]. \n",
    "    Adapted from: https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/pmip3_pcoral.py\n",
    "    \n",
    "    INPUTS:  \n",
    "        - ft: filename for SST field, with variable name tname [default = 'tos']\n",
    "        - fs: filename object field, with variable name sname [default = 'sos']\n",
    "        \n",
    "    RETURNS\n",
    "        - eastern_vars, central_vars, western_vars: tuples of objects --> \n",
    "          e_tobj, e_sos_latobj, e_sos_lonobj, e_coral2, e_tosContri, e_sosContri\n",
    "\n",
    "    [1] Thompson, D. M. , T. R. Ault , M. N. Evans , J. E. Cole , \n",
    "    and J. Emile-Geay (2011), Comparison of observed and simulated tropical \n",
    "    climate trends using a forward model of coral δ18O, Geophys. Res. Lett., \n",
    "    38, L14706, doi:10.1029/2011GL048224.\n",
    "    \n",
    "    '''\n",
    "  \n",
    "    print('***starting coral_sensor_apply***')\n",
    "    \n",
    "    # get the start and end time steps\n",
    "    start_time_sos = fs.time[0] \n",
    "    end_time_sos   = fs.time[-1]\n",
    "    start_time_tos = ft.time[0]\n",
    "    end_time_tos   = ft.time[-1]\n",
    "    \n",
    "    print('getting variables & lat/lon objects')\n",
    "    sos_latobj, sos_lonobj = get_coord_names(fs)\n",
    "    \n",
    "    # EAST PACIFIC: -10, 0, 270, 280\n",
    "    e_IPsosVar, e_IPtosVar, e_sos_latobj, e_sos_lonobj = \\\n",
    "    get_pacific_coords(sos_latobj, sos_lonobj, fs, ft, -10, 0, 270, 280) \n",
    "    \n",
    "    # CENTRAL PACIFIC: -5, 5, 190, 240\n",
    "    c_IPsosVar, c_IPtosVar, c_sos_latobj, c_sos_lonobj = \\\n",
    "    get_pacific_coords(sos_latobj, sos_lonobj, fs, ft, -5, 5, 190, 240) \n",
    "\n",
    "    # WEST PACIFIC: -20, 0, 120, 180\n",
    "    w_IPsosVar, w_IPtosVar, w_sos_latobj, w_sos_lonobj = \\\n",
    "    get_pacific_coords(sos_latobj, sos_lonobj, fs, ft, -20, 0, 120, 180) \n",
    "    \n",
    "\n",
    "    e_tobj, \\\n",
    "    e_sos_latobj, \\\n",
    "    e_sos_lonobj, \\\n",
    "    e_coral2, \\\n",
    "    e_tosContri, \\\n",
    "    e_sosContri = compute_corals(e_IPsosVar,e_IPtosVar,e_sos_latobj,e_sos_lonobj)\n",
    "    \n",
    "    c_tobj, \\\n",
    "    c_sos_latobj, \\\n",
    "    c_sos_lonobj, \\\n",
    "    c_coral2, \\\n",
    "    c_tosContri, \\\n",
    "    c_sosContri = compute_corals(c_IPsosVar,c_IPtosVar,c_sos_latobj,c_sos_lonobj)\n",
    "    \n",
    "    w_tobj, \\\n",
    "    w_sos_latobj, \\\n",
    "    w_sos_lonobj, \\\n",
    "    w_coral2, \\\n",
    "    w_tosContri, \\\n",
    "    w_sosContri = compute_corals(w_IPsosVar,w_IPtosVar,w_sos_latobj,w_sos_lonobj)\n",
    "    \n",
    "    eastern_vars = e_tobj, e_sos_latobj, e_sos_lonobj, e_coral2, e_tosContri, e_sosContri\n",
    "    central_vars = c_tobj, c_sos_latobj, c_sos_lonobj, c_coral2, c_tosContri, c_sosContri\n",
    "    western_vars = w_tobj, w_sos_latobj, w_sos_lonobj, w_coral2, w_tosContri, w_sosContri\n",
    "    \n",
    "    ###########################\n",
    "    # create a dictionary to store corals\n",
    "    corals = {}\n",
    "    corals['east'] = e_coral2\n",
    "    corals['central'] = c_coral2\n",
    "    corals['west'] = w_coral2\n",
    "    \n",
    "    # save dictionary to a pickle file\n",
    "    pickle.dump(corals, open(base + 'corals/coral_{}_{}.p'.format(expt, model), \"wb\" ))\n",
    "\n",
    "    # save .mat\n",
    "    io.savemat(base + 'corals/coral_{}_{}.mat'.format(expt, model), corals)\n",
    "\n",
    "    print(\"saved!\")\n",
    "    \n",
    "    return eastern_vars, central_vars, western_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandpass & bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    '''\n",
    "    Adapted from https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/bandpass.py\n",
    "    '''\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    '''\n",
    "    Adapted from https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/bandpass.py\n",
    "    '''\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap method is a statistical technique for estimating quantities about a population by averaging estimates from multiple small data samples. Samples are constructed by drawing observations from a large data sample one at a time and returning them to the data sample after they have been chosen. This allows a given observation to be included in a given small sample more than once. This approach to sampling is called sampling with replacement.\n",
    "\n",
    "<h6>Moving blocks sampling</h6>\n",
    "Break the series into roughly equal-length blocks of consecutive observations, to resample the block with replacement, and then paste the blocks together. There are $(n - b + 1)$ such blocks available, with consecutive samples of length b. This preserves dependency in the original samples to length b. \n",
    "\n",
    "For each boostrap sample, randomly select blocks and assemble into a length-n timeseries, then compute $\\hat{\\beta}^*$ for each such length-n series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_bootstrap_ET(X, Lb, Nb): \n",
    "    \n",
    "    '''\n",
    "    Implement Block Bootstrap as in: \n",
    "    http://nbviewer.ipython.org/github/welch/stats-notebooks/\n",
    "    blob/master/SubsamplingBootstrap.ipynb.\n",
    "    Adapted from https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/bootstrap.py.\n",
    "    \n",
    "    INPUTS:\n",
    "        - X: the bootstrap sample, array\n",
    "        - Lb: needed to sample multiples of 12 years\n",
    "        - Nb: number of bootstrap samples \n",
    "    \n",
    "    RETURNS:\n",
    "        - Xb: numpy array, resampled version, or \"replicate\" of data\n",
    "    '''\n",
    "    \n",
    "    nt = len(X)\n",
    "    ns = int(np.ceil(nt/Lb))\n",
    "    Xb = np.zeros((Nb, nt))\n",
    "\n",
    "    for b in range(Nb):       \n",
    "        for block_i, start in enumerate(np.random.randint(nt - Lb + 1, size=ns)):\n",
    "            try:\n",
    "                Xb[b, block_i*Lb:(block_i+1)*Lb] = X[start:start+Lb]\n",
    "            except ValueError: \n",
    "            # changing Lb to 12 as 24 would make (block_i+1)*Lb out of range for X\n",
    "                Xb[b, block_i*12:(block_i+1)*12] = X[start:start+12]\n",
    "\n",
    "    return Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_cycle(Xb):\n",
    "    \n",
    "    '''\n",
    "    Compute and isolate the seasonal cycle.\n",
    "    Adapted from https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/pcoral_bootstrap.py\n",
    "    \n",
    "    INPUTS:\n",
    "        - Xb: numpy array, resampled version, or \"replicate\" of data\n",
    "    \n",
    "    RETURNS:\n",
    "        - clim:\n",
    "        - anom:\n",
    "    '''\n",
    "    \n",
    "    nb,nt = Xb.shape\n",
    "    ny    = int(nt/12)\n",
    "    clim  = np.empty((nb,12))\n",
    "\n",
    "    for i in range(12):\n",
    "        clim[:,i] = Xb[:,i::12].mean(axis=1)\n",
    "    print(\"clim\", clim.shape)\n",
    "\n",
    "    anom = Xb - np.tile(clim,(1, ny))\n",
    "    \n",
    "    return clim, anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer(coral, Nb, Lb, windows):\n",
    "    \n",
    "    '''\n",
    "    Compute variance & seasonal amplitude.\n",
    "    Adapted from https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/pcoral_bootstrap.py\n",
    "    \n",
    "    INPUTS:\n",
    "        - coral:\n",
    "        - Nb: number of bootstrap samples \n",
    "        - Lb: needed to sample multiples of 12 years\n",
    "        - windows: sampling windows\n",
    "    \n",
    "    RETURNS:\n",
    "        - variance, seasonal_amp:\n",
    "    '''\n",
    "\n",
    "    # filtering parameters    \n",
    "    fs = 1\n",
    "    f_hi = 1/(12*2.0)\n",
    "    f_lo = fs/(12*7.0)\n",
    "    \n",
    "    # compute spatial mean\n",
    "    spatial_mean = coral.mean(axis=(1,2))\n",
    "    print(\"spatial_mean\", spatial_mean.shape)\n",
    "    print(\"coral\", coral.shape)\n",
    "    \n",
    "    # generate boostrap samples\n",
    "    Xb = block_bootstrap_ET(spatial_mean, Lb, Nb)\n",
    "    nw = len(windows) # number of windows\n",
    "   \n",
    "    seasonal_amp = np.empty((nw, Nb))\n",
    "    variance = np.empty((nw, Nb))\n",
    "    \n",
    "    index = 0  # loop over windows\n",
    "    for i in windows:\n",
    "        Xw =  Xb[:, :i*12]  # sample over window\n",
    "        clim, anom = seasonal_cycle(Xw)  # isolate seasonal cycle\n",
    "        # compute seasonal amplitude\n",
    "        smax = np.nanmax(clim, axis=1)\n",
    "        smin = np.nanmin(clim, axis=1)\n",
    "        seasonal_amp[index, :] = smax - smin\n",
    "        \n",
    "        # compute ENSO variance\n",
    "        anom2_7 = np.empty(anom.shape)\n",
    "        for b in range(Nb):\n",
    "            # apply bandpass filter        \n",
    "            anom2_7[b, :] = butter_bandpass_filter(anom[b,:], f_lo, f_hi, fs)\n",
    "        # compute variance per se     \n",
    "        variance[index,:]  = np.var(anom2_7,axis=1)\n",
    "        index +=1  # update index\n",
    "        \n",
    "    return (variance, seasonal_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "def create_stats(tos_data, sos_data, expt, model):\n",
    "    \n",
    "    '''\n",
    "    Creates and stores statistics.\n",
    "    Adapted from https://github.com/CommonClimate/EmileGeay_NatGeo2015/blob/\n",
    "    master/code/python/pmip3_pcoral_bootstrap.py\n",
    "    \n",
    "    INPUTS:\n",
    "        - tos_data\n",
    "        - sos_data\n",
    "\n",
    "    \n",
    "    RETURNS:\n",
    "        - variance, seasonal_amp:\n",
    "    '''\n",
    "\n",
    "    # This script uses block bootstrap to randomize coral data [uses different \n",
    "    # sampling time length to generate distribution plot of seasonal cycle amplitude]?\n",
    "    \n",
    "    eastern_vars, central_vars, western_vars = coral_sensor_apply(tos_data, \n",
    "                                                                  sos_data, \n",
    "                                                                  expt, model)\n",
    "\n",
    "    Nb = 1000 # number of bootstrap samples \n",
    "    Lb = 24 # needed to sample multiples of 12 years\n",
    "    windows = [50] # observation windows\n",
    "    nw = windows.__len__()\n",
    "\n",
    "    pcoral_boot_exp = {}; variance = {}; seasonal_amp = {}\n",
    "\n",
    "    # compute bootstrapped climate statistics on the three AOI\n",
    "    variance_e, seasonal_amp_e = computer(eastern_vars[3], Nb, Lb, windows)\n",
    "    variance_c, seasonal_amp_c = computer(central_vars[3], Nb, Lb, windows)\n",
    "    variance_w, seasonal_amp_w = computer(western_vars[3], Nb, Lb, windows)\n",
    "\n",
    "    # store variance results\n",
    "    variance = np.empty((3*nw, Nb))\n",
    "\n",
    "    variance[0:nw, :] = variance_e\n",
    "    variance[nw:2*nw, :] = variance_c\n",
    "    variance[2*nw:3*nw, :] = variance_w\n",
    "\n",
    "    # store seasonal amplitude results\n",
    "    seasonal_amp = np.empty((3*nw, Nb))\n",
    "    seasonal_amp[0:nw, :] = seasonal_amp_e\n",
    "    seasonal_amp[nw:2*nw, :] = seasonal_amp_c\n",
    "    seasonal_amp[2*nw:3*nw, :] = seasonal_amp_w\n",
    "\n",
    "    pcoral_boot_exp['var'] = variance\n",
    "    pcoral_boot_exp['seas'] = seasonal_amp   \n",
    "\n",
    "    print(variance.shape, seasonal_amp.shape) # 0:6=east, 6:12=central, 12:18=west\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    ###########################\n",
    "    \n",
    "    # save dictionary to a pickle file\n",
    "    pickle.dump(pcoral_boot_exp, open( base + 'bootstrapped_corals/pcoral_bootstrap_{}_{}.p'. \\\n",
    "               format(expt, model), \"wb\" ))\n",
    "\n",
    "    # save .mat\n",
    "    io.savemat(base + 'bootstrapped_corals/pcoral_bootstrap_{}_{}.mat'. \\\n",
    "               format(expt, model), pcoral_boot_exp)\n",
    "\n",
    "    print(\"saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOING MODEL:  FGOALS-f3-L\n",
      "***starting coral_sensor_apply***\n",
      "getting variables & lat/lon objects\n",
      "***getting curvi coordinates***\n",
      "(1200, 218, 360) --> (1200, 17, 10)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(1200, 218, 360) --> (1200, 17, 10)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(218, 360) --> (17, 10)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(218, 360) --> (17, 10)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(1200, 218, 360) --> (1200, 18, 50)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(1200, 218, 360) --> (1200, 18, 50)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(218, 360) --> (18, 50)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(218, 360) --> (18, 50)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(1200, 218, 360) --> (1200, 30, 60)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(1200, 218, 360) --> (1200, 30, 60)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(218, 360) --> (30, 60)\n",
      "***finished curvi coordinates***\n",
      "***getting curvi coordinates***\n",
      "(218, 360) --> (30, 60)\n",
      "***finished curvi coordinates***\n",
      "***starting compute_corals***\n",
      "creating lat/lon arrays\n",
      "***doing coral_sensor_field***\n",
      "centering the fields\n",
      "assigning b-values\n",
      "storing b-values\n",
      "calculating contributions\n",
      "***finished coral_sensor_field***\n",
      "creating masked arrays\n",
      "***finished compute_corals***\n",
      "***starting compute_corals***\n",
      "creating lat/lon arrays\n",
      "***doing coral_sensor_field***\n",
      "centering the fields\n",
      "assigning b-values\n",
      "storing b-values\n",
      "calculating contributions\n",
      "***finished coral_sensor_field***\n",
      "creating masked arrays\n",
      "***finished compute_corals***\n",
      "***starting compute_corals***\n",
      "creating lat/lon arrays\n",
      "***doing coral_sensor_field***\n",
      "centering the fields\n",
      "assigning b-values\n",
      "storing b-values\n",
      "calculating contributions\n",
      "***finished coral_sensor_field***\n",
      "creating masked arrays\n",
      "***finished compute_corals***\n",
      "saved!\n",
      "spatial_mean (1200,)\n",
      "coral (1200, 17, 10)\n",
      "clim (1000, 12)\n",
      "spatial_mean (1200,)\n",
      "coral (1200, 18, 50)\n",
      "clim (1000, 12)\n",
      "spatial_mean (1200,)\n",
      "coral (1200, 30, 60)\n",
      "clim (1000, 12)\n",
      "(3, 1000) (3, 1000)\n",
      "Done!\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(new_sos_models_mh):\n",
    "    outfile='corals/coral_mh_MODNAME.mat'\n",
    "    already_exists=os.path.isfile(outfile.replace('MODNAME',new_sos_models_mh[i]))\n",
    "    if not already_exists:\n",
    "        print(\"DOING MODEL: \",  new_sos_models_mh[i])\n",
    "        create_stats(tos_data_mh[i], sos_data_mh[i], 'mh', new_sos_models_mh[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(new_sos_models_ctrl):\n",
    "    outfile='corals/coral_ctrl_MODNAME.mat'\n",
    "    already_exists=os.path.isfile(outfile.replace('MODNAME',new_sos_models_ctrl[i]))\n",
    "    if not already_exists:\n",
    "        print(\"DOING MODEL: \",  new_sos_models_ctrl[i])\n",
    "        create_stats(tos_data_ctrl[i], sos_data_ctrl[i], 'ctrl', new_sos_models_ctrl[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(new_sos_models_hi):\n",
    "    outfile='corals/coral_hi_MODNAME.mat'\n",
    "    already_exists=os.path.isfile(outfile.replace('MODNAME',new_sos_models_hi[i]))\n",
    "    if not already_exists:\n",
    "        print(\"DOING MODEL: \",  new_sos_models_hi[i])\n",
    "        create_stats(tos_data_hi[i], sos_data_hi[i], 'hi', new_sos_models_hi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
